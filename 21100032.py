# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PLBjkkCuiz9G_kaSIfk1t1uA3HEt_lDC

# Imports
"""

import numpy as np
import scipy as sp
import pandas as pd
from matplotlib import pyplot 
import re
import glob
from collections import Counter

from google.colab import drive
drive.mount('/content/drive')



!gdown --id 1HKHlbOmzsOHcjQ7msreZWAtYOTmkha7_
!unzip "IMDB_Dataset.zip" -d "/content/Assignment4"

"""# PreProcessing"""

stopWords = open("/content/Assignment4/Dataset/stop_words.txt")
stopWordsList = stopWords.readlines()

# stopWordsList

stopListNoNewLine = []
for x in stopWordsList[:-1]:
    stopListNoNewLine.append(x[:-1])

stopListNoNewLine.append(stopWordsList[-1])

posTrainList = []
negTrainList = []
labelNeg = []
labelPos = []

for negTrainFile in glob.glob("/content/Assignment4/Dataset/train/neg/*"):
    negRev = open(negTrainFile)
    eachRevNeg = negRev.readlines()
    negTrainList.append(eachRevNeg[0])
    labelNeg.append(0)
    
    
for posTrainFile in glob.glob("/content/Assignment4/Dataset/train/pos/*"):
    posRev = open(posTrainFile ,encoding="utf8")
    eachRevPos = posRev.readlines()
    posTrainList.append(eachRevPos[0])
    labelPos.append(1)

# negTrainList

negativeReviews = []
negRevFull = []
negRevWords = []

for eachNegRev in negTrainList:
  negativeReviews.append(re.sub('[^\w\s]+', ' ', eachNegRev))

# negativeReviews

for eachNegRev in negativeReviews:
    lowerRev = eachNegRev.casefold()
    negRevWords = lowerRev.split()
    for eachNegRevWord in negRevWords:
        for eachStopWord in stopListNoNewLine:
            if eachStopWord in negRevWords:
                negRevWords.remove(eachStopWord)
    negString = ' '.join(negRevWords)
    negRevFull.append(negString)

# negRevFull

# len(negRevFull)

# posTrainList

positiveReviews = []
posRevFull = []
posRevWords = []

for eachPosRev in posTrainList:
  positiveReviews.append(re.sub('[^\w\s]+', ' ', eachPosRev))

# positiveReviews

for eachPosRev in positiveReviews:
    lowerPosRev = eachPosRev.casefold()
    posRevWords = lowerPosRev.split()
    for eachPosRevWord in posRevWords:
        for eachStopWord in stopListNoNewLine:
            if eachStopWord in posRevWords:
                posRevWords.remove(eachStopWord)
    posString = ' '.join(posRevWords)
    posRevFull.append(posString)

# len(posRevFull)

labelsTrain = labelNeg + labelPos

# labelsTrain

posTestList = []
negTestList = []
labelTestNeg = []
labelTestPos = []

for negTestFile in glob.glob("/content/Assignment4/Dataset/test/neg/*"):
    negTestRev = open(negTestFile)
    eachRevNegTest = negTestRev.readlines()
    negTestList.append(eachRevNegTest[0])
    labelTestNeg.append(0)
    
    
for posTestFile in glob.glob("/content/Assignment4/Dataset/test/pos/*"):
    posTestRev = open(posTestFile ,encoding="utf8")
    eachRevPosTest = posTestRev.readlines()
    posTestList.append(eachRevPosTest[0])
    labelTestPos.append(1)

# negTestList

negativeTestReviews = []
negTestRevFull = []
negTestRevWords = []

for eachNegTestRev in negTestList:
  negativeTestReviews.append(re.sub('[^\w\s]+', ' ', eachNegTestRev))

for eachNegTestRev in negativeTestReviews:
    lowerTestRev = eachNegTestRev.casefold()
    negTestRevWords = lowerTestRev.split()
    for eachNegTestRevWord in negTestRevWords:
        for eachStopWord in stopListNoNewLine:
            if eachStopWord in negTestRevWords:
                negTestRevWords.remove(eachStopWord)
    negTestString = ' '.join(negTestRevWords)
    negTestRevFull.append(negTestString)

# negTestRevFull

positiveTestReviews = []
posTestRevFull = []
posTestRevWords = []

for eachPosTestRev in posTestList:
  positiveTestReviews.append(re.sub('[^\w\s]+', ' ', eachPosTestRev))

for eachPosTestRev in positiveTestReviews:
    lowerPosTestRev = eachPosTestRev.casefold()
    posTestRevWords = lowerPosTestRev.split()
    for eachPosTestRevWord in posTestRevWords:
        for eachStopWord in stopListNoNewLine:
            if eachStopWord in posTestRevWords:
                posTestRevWords.remove(eachStopWord)
    posTestString = ' '.join(posTestRevWords)
    posTestRevFull.append(posTestString)

# len(posTestRevFull)

labelsTest = labelTestNeg + labelTestPos

# len(labelsTest)

trainingReviews = negRevFull + posRevFull
testingReviews = negTestRevFull + posTestRevFull

# len(trainingReviews)

# len(testingReviews)

"""# Part 1"""

vocabTotal = Counter()
for eachReview in trainingReviews:
  for eachWord in eachReview.split():
    vocabTotal[eachWord] += 1

len(vocabTotal)

vocabPos = Counter()
for eachPosRev in posRevFull:
  for eachWord in eachPosRev.split():
    vocabPos[eachWord] += 1

len(vocabPos)

vocabNeg = Counter()
for eachNegRev in negRevFull:
  for eachWord in eachNegRev.split():
    vocabNeg[eachWord] += 1

len(vocabNeg)

countNeg = 0
countPos = 0

for negtweet in negRevFull:
  words = negtweet.split()
  for word in words:
    countNeg += 1

for postweet in posRevFull:
  words = postweet.split()
  for word in words:
    countPos += 1

def trainNaiveBayes(D):
  Ndoc = len(D)
  Nc = [len(negRevFull), len(posRevFull)]
  logPrior = [np.log(Nc[0]/Ndoc), np.log(Nc[1]/Ndoc)]

  loglikelihood = Counter()

  for eachWord in vocabTotal:
    count0 = vocabNeg[eachWord]
    count1 = vocabPos[eachWord]

    loglikelihood[(eachWord, 0)] = np.log((count0+1)/(countNeg+len(vocabTotal)+1))
    loglikelihood[(eachWord, 1)] = np.log((count1+1)/(countPos+len(vocabTotal)+1))

  return logPrior, loglikelihood

def testNaiveBayes(testDoc, logPrior, loglikelihood):
  sum = [logPrior[0], logPrior[1]]

  for word in testDoc:
    if word in vocabTotal.keys():
      sum[0] = sum[0] + loglikelihood[(word, 0)]
      sum[1] = sum[1] + loglikelihood[(word, 1)]

  sum = np.array(sum)
  return np.argmax(sum)

logPrior, loglikelihood = trainNaiveBayes(trainingReviews)

ypred = []

for tweets in testingReviews:
  words = tweets.split()
  pred = testNaiveBayes(words, logPrior, loglikelihood)
  ypred.append(pred)

ypred = np.array(ypred)

correct = 0
for i in range(25000):
  if (ypred[i] == labelsTest[i]):
    correct += 1

accuracy = correct/len(labelsTest)

print("Accuracy is ", accuracy*100, "%")

"""# Part 2"""

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

vectorizer = CountVectorizer()
trainReviews = vectorizer.fit_transform(trainingReviews)
testReviews = vectorizer.transform(testingReviews)

multi = MultinomialNB()
multi.fit(trainReviews, labelsTrain)
pred = multi.predict(testReviews)

accuracy = accuracy_score(pred, labelsTest)
print("Accuracy is ",accuracy*100, "%")

confMat = confusion_matrix(pred, labelsTest)
print("Confusion Matrix: \n", confMat)